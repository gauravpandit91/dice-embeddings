{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f096e66a",
   "metadata": {},
   "source": [
    "# Train and Evaluate a KGE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913b10b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dicee \n",
    "%pip install dicee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf3fe02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dice/anaconda3/envs/dice/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dicee import KGE, Execute\n",
    "from dicee.config import Args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168ae7ac",
   "metadata": {},
   "source": [
    "# How to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66a3f46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dicee.config.Args at 0x7f210382f7f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) Load Default Params\n",
    "args=Args()\n",
    "# (2) Select a Dataset and a KGE\n",
    "args.path_dataset_folder=\"../KGs/UMLS\"\n",
    "args.model=\"LFMult\"\n",
    "args.embedding_dim=32\n",
    "args.num_epochs=25\n",
    "args.num_of_output_channels= 32\n",
    "args.batch_size=10#24\n",
    "args.scoring_technique=\"NegSample\"\n",
    "args.eval_model=\"train_val_test\"\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c21f128d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acquired_abnormality\tlocation_of\texperimental_model_of_disease\n",
      "anatomical_abnormality\tmanifestation_of\tphysiologic_function\n",
      "alga\tisa\tentity\n",
      "mental_or_behavioral_dysfunction\taffects\texperimental_model_of_disease\n",
      "health_care_activity\tassociated_with\tanatomical_abnormality\n",
      "population_group\tinteracts_with\tage_group\n",
      "clinical_attribute\tresult_of\tnatural_phenomenon_or_process\n",
      "body_part_organ_or_organ_component\tlocation_of\tbiologic_function\n",
      "biologically_active_substance\tcomplicates\tanatomical_abnormality\n",
      "disease_or_syndrome\tresult_of\tacquired_abnormality\n"
     ]
    }
   ],
   "source": [
    "!head ../KGs/UMLS/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "885bc8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor=Execute(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f39f407",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time:2023-08-24 13:21:04.457473\n",
      "*** Read or Load Knowledge Graph  ***\n",
      "*** Reading ../KGs/UMLS/train.txt with Pandas ***\n",
      "Reading with pandas.read_csv with sep ** s+ ** ...\n",
      "Took 0.0608 seconds | Current Memory Usage  446.91 in MB\n",
      "*** Reading ../KGs/UMLS/valid.txt with Pandas ***\n",
      "Reading with pandas.read_csv with sep ** s+ ** ...\n",
      "Took 0.0164 seconds | Current Memory Usage  446.92 in MB\n",
      "*** Reading ../KGs/UMLS/test.txt with Pandas ***\n",
      "Reading with pandas.read_csv with sep ** s+ ** ...\n",
      "Took 0.0153 seconds | Current Memory Usage  446.97 in MB\n",
      "\n",
      "Concatenating data to obtain index...\n",
      "Done !\n",
      "\n",
      "Creating a mapping from entities to integer indexes...\n",
      "Done !\n",
      "\n",
      "Done ! 0.016 seconds\n",
      "\n",
      "Done !\n",
      "\n",
      "Done !\n",
      "\n",
      "Took 0.0368 seconds | Current Memory Usage  446.99 in MB\n",
      "Data Type conversion...\n",
      "Submit er-vocab, re-vocab, and ee-vocab via  ProcessPoolExecutor...\n",
      "Preprocessing took: 0.206 seconds\n",
      "\n",
      "------------------- Description of Dataset ../KGs/UMLS -------------------\n",
      "Number of entities:135\n",
      "Number of relations:46\n",
      "Number of triples on train set:5216\n",
      "Number of triples on valid set:652\n",
      "Number of triples on test set:661\n",
      "Entity Index:0.00000 in GB\n",
      "Relation Index:0.00000 in GB\n",
      "Train set :0.00003 in GB\n",
      "\n",
      "# of CPUs:4 | # of GPUs:0 | # of CPUs for dataloader:0\n",
      "------------------- Train -------------------\n",
      "Initializing TorchTrainer CPU Trainer...\tTook 0.0054 seconds | Current Memory Usage  447.04 in MB\n",
      "Initializing Model...\t"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m report\u001b[39m=\u001b[39mexecutor\u001b[39m.\u001b[39;49mstart()\n",
      "File \u001b[0;32m~/anaconda3/envs/dice/lib/python3.10/site-packages/dicee/executer.py:205\u001b[0m, in \u001b[0;36mExecute.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m DICE_Trainer(args\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs,\n\u001b[1;32m    199\u001b[0m                             is_continual_training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_continual_training,\n\u001b[1;32m    200\u001b[0m                             storage_path\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage_path,\n\u001b[1;32m    201\u001b[0m                             evaluator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluator,\n\u001b[1;32m    202\u001b[0m                             dataset\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset  \u001b[39m# only used for Pykeen's models\u001b[39;00m\n\u001b[1;32m    203\u001b[0m                             )\n\u001b[1;32m    204\u001b[0m \u001b[39m# (4) Start the training\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrained_model, form_of_labelling \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mstart(dataset\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset)\n\u001b[1;32m    206\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend(form_of_labelling)\n",
      "File \u001b[0;32m~/anaconda3/envs/dice/lib/python3.10/site-packages/dicee/trainer/dice_trainer.py:207\u001b[0m, in \u001b[0;36mDICE_Trainer.start\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer: Union[TorchTrainer, TorchDDPTrainer, pl\u001b[39m.\u001b[39mTrainer]\n\u001b[1;32m    206\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize_trainer(callbacks\u001b[39m=\u001b[39mget_callbacks(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs), plugins\u001b[39m=\u001b[39m[])\n\u001b[0;32m--> 207\u001b[0m model, form_of_labelling \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitialize_or_load_model()\n\u001b[1;32m    208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mevaluator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluator\n\u001b[1;32m    209\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mdataset \u001b[39m=\u001b[39m dataset\n",
      "File \u001b[0;32m~/anaconda3/envs/dice/lib/python3.10/site-packages/dicee/static_funcs.py:37\u001b[0m, in \u001b[0;36mtimeit.<locals>.timeit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtimeit_wrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     36\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m---> 37\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     38\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m     39\u001b[0m     total_time \u001b[39m=\u001b[39m end_time \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/envs/dice/lib/python3.10/site-packages/dicee/trainer/dice_trainer.py:165\u001b[0m, in \u001b[0;36mDICE_Trainer.initialize_or_load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39m@timeit\u001b[39m\n\u001b[1;32m    163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minitialize_or_load_model\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    164\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mInitializing Model...\u001b[39m\u001b[39m'\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m     model, form_of_labelling \u001b[39m=\u001b[39m select_model(\u001b[39mvars\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mis_continual_training, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_path,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset)\n\u001b[1;32m    166\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreport[\u001b[39m'\u001b[39m\u001b[39mform_of_labelling\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m form_of_labelling\n\u001b[1;32m    167\u001b[0m     \u001b[39massert\u001b[39;00m form_of_labelling \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mEntityPrediction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRelationPrediction\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/dice/lib/python3.10/site-packages/dicee/static_funcs.py:75\u001b[0m, in \u001b[0;36mselect_model\u001b[0;34m(args, is_continual_training, storage_path, dataset)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m model, _\n\u001b[1;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m intialize_model(args, dataset)\n",
      "File \u001b[0;32m~/anaconda3/envs/dice/lib/python3.10/site-packages/dicee/static_funcs.py:376\u001b[0m, in \u001b[0;36mintialize_model\u001b[0;34m(args, dataset)\u001b[0m\n\u001b[1;32m    373\u001b[0m     form_of_labelling \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mEntityPrediction\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    374\u001b[0m \u001b[39m# elif for PYKEEN https://github.com/dice-group/dice-embeddings/issues/54\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[39mreturn\u001b[39;00m model, form_of_labelling\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "report=executor.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e561c776",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m report\n",
      "\u001b[0;31mNameError\u001b[0m: name 'report' is not defined"
     ]
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a85a075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**(5%3)*2**(9%3) == 2**((5+9)%3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2d5d3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5970, -1.2309, -0.2645, -1.7455])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(42)  \n",
    "A = torch.randn(4, 3)\n",
    "B = torch.randn(4, 3)\n",
    "C = torch.randn(4, 3)\n",
    "\n",
    "i, j, k = torch.meshgrid(torch.arange(3), torch.arange(3), torch.arange(3))\n",
    "mask = i + j == k\n",
    "s11 = torch.sum(torch.where(~mask, torch.zeros_like(~mask),  A[:, i] * B[:, j] *C[:, k]),dim=(-3,-2,-1))\n",
    "s22 = torch.sum(torch.where(mask, torch.zeros_like(mask), torch.sin(i + j - k) / (i + j - k) * A[:, i] * B[:, j] * C[:, k]),dim=(-3,-2,-1))\n",
    "\n",
    "score = s11 + s22\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "980e8f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False]],\n",
       "\n",
       "        [[False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False]],\n",
       "\n",
       "        [[False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "117ff172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5/\\\n",
    ".5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8048736e",
   "metadata": {},
   "source": [
    "# How to Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96c6dabd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pre_trained_model\u001b[39m=\u001b[39mKGE(path\u001b[39m=\u001b[39mreport[\u001b[39m'\u001b[39m\u001b[39mpath_experiment_folder\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'report' is not defined"
     ]
    }
   ],
   "source": [
    "pre_trained_model=KGE(path=report['path_experiment_folder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model.predict_topk(head_entity=['behavior'],relation=['associated_with'],topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f6f89",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pre_trained_model.find_missing_triples(confidence=0.8,\n",
    "                                       entities=['behavior'],\n",
    "                                       relations=['associated_with'],topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60dce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is already saved\n",
    "!ls Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fc46d4",
   "metadata": {},
   "source": [
    "# How to deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab54c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained model can be used with anyone\n",
    "pre_trained_model.deploy(share=True,top_k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
